{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Add a column at the end of the English and Italian data frames named ‘LANGUAGE’ which identifies the language of the ‘TEXT’ column. Create a single data frame by concatenating both the English and Italian data frames into one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         TARGET POS  INDEX                                               TEXT  \\\n",
      "0   achievement   N      3  Bring up academic achievements , awards , and ...   \n",
      "1   achievement   N      9  Please list people you have helped , your pers...   \n",
      "2      activate   V      1     Add activated carbon straight to your vodka .    \n",
      "3      activate   V     15  Place sensors around your garden , and when a ...   \n",
      "4     adventure   N      9  Look for a partner that shares your level of a...   \n",
      "..          ...  ..    ...                                                ...   \n",
      "95       verità   N      8  In un modo o nell' altro , la verità viene sem...   \n",
      "96      viaggio   N      2  Organizza dei viaggi nel fine settimana quando...   \n",
      "97      viaggio   N      6  Pesa le tue valigie prima del viaggio per evit...   \n",
      "98        vista   N      6  è molto importante non perdere di vista la pro...   \n",
      "99        vista   N      9  i conigli hanno un ottimo udito e un' ottima v...   \n",
      "\n",
      "    MEAN LANGUAGE  \n",
      "0   3.06  ENGLISH  \n",
      "1   3.03  ENGLISH  \n",
      "2   3.83  ENGLISH  \n",
      "3   5.51  ENGLISH  \n",
      "4   2.03  ENGLISH  \n",
      "..   ...      ...  \n",
      "95  2.53  ITALIAN  \n",
      "96  5.03  ITALIAN  \n",
      "97  4.84  ITALIAN  \n",
      "98  2.22  ITALIAN  \n",
      "99  5.13  ITALIAN  \n",
      "\n",
      "[200 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "english = pd.read_csv(\"CONcreTEXT_trial_EN.tsv\", sep='\\t')\n",
    "italian = pd.read_csv(\"CONcreTEXT_trial_IT.tsv\", sep='\\t')\n",
    "english[\"LANGUAGE\"] = \"ENGLISH\"\n",
    "italian[\"LANGUAGE\"] = \"ITALIAN\"\n",
    "combined = pd.concat([english, italian])\n",
    "print(combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Using the sklearn classes CountVectorizer and TfidfTransformer create a training set using *all rows* of the ‘TEXT’ column from your merged dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(combined[\"TEXT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 1330)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1285"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.vocabulary_.get('vista')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 1330)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Train and fit a Multinomial Naive Bayes algorithm on the training data. The target variable is the ‘LANGUAGE’ column in your merged dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB().fit(X_train_tfidf, combined[\"LANGUAGE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Use your model to predict the language of the following two sentences: docs_new = ['Why does a rose smell sweet?', 'Pensa ai tuoi sentimenti di amore.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why does a rose smell sweet? => ENGLISH\n",
      "Pensa ai tuoi sentimenti di amore. => ITALIAN\n",
      "Brang ip => ENGLISH\n"
     ]
    }
   ],
   "source": [
    "docs_new = ['Why does a rose smell sweet?', 'Pensa ai tuoi sentimenti di amore.', 'Brang ip']\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "    print(doc + \" => \" + category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: Test your model on at least 5 other sentences of your own choosing (both English and Italian) and report your results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not be ruled by fear => ENGLISH\n",
      "winning half the battle => ENGLISH\n",
      "nail on the head => ENGLISH\n",
      "hang in there => ENGLISH\n",
      "on the ball => ENGLISH\n"
     ]
    }
   ],
   "source": [
    "docs_new_test = ['not be ruled by fear', 'winning half the battle',\n",
    "                 'nail on the head', 'hang in there', 'on the ball']\n",
    "X_new_counts_test = count_vect.transform(docs_new_test)\n",
    "X_new_tfidf_test = tfidf_transformer.transform(X_new_counts_test)\n",
    "predicted_test = clf.predict(X_new_tfidf_test)\n",
    "\n",
    "for doc, category in zip(docs_new_test, predicted_test):\n",
    "    print(doc + \" => \" + category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C’è un treno alle => ITALIAN\n",
      "È stato un piacere conoscerla => ITALIAN\n",
      "tutta la colpa e => ITALIAN\n",
      "casa illegale in => ITALIAN\n",
      "amore e gentilezza => ITALIAN\n"
     ]
    }
   ],
   "source": [
    "docs_new_italian_test = ['C’è un treno alle', 'È stato un piacere conoscerla',\n",
    "                 'tutta la colpa e', 'casa illegale in', 'amore e gentilezza']\n",
    "X_new_counts_italian_test = count_vect.transform(docs_new_italian_test)\n",
    "X_new_tfidf_italian_test = tfidf_transformer.transform(X_new_counts_italian_test)\n",
    "predicted__italian_test = clf.predict(X_new_tfidf_italian_test)\n",
    "\n",
    "for doc, category in zip(docs_new_italian_test, predicted__italian_test):\n",
    "    print(doc + \" => \" + category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Credit: Bonus points for testing the model on a sentence of your own that the model predicts incorrectly. For example, input an English sentence but the model predicts Italian. Or vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a meeting in scenario club => ITALIAN\n"
     ]
    }
   ],
   "source": [
    "bonus_test = [\"a meeting in scenario club\"]\n",
    "X_new_counts_test1 = count_vect.transform(bonus_test)\n",
    "X_new_tfidf_test1 = tfidf_transformer.transform(X_new_counts_test1)\n",
    "predicted_test1 = clf.predict(X_new_tfidf_test1)\n",
    "\n",
    "for doc, category in zip(bonus_test, predicted_test1):\n",
    "    print(doc + \" => \" + category)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
