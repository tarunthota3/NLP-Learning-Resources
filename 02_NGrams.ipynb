{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1: First, you will need to load the words in English and Italian in two separate lists and then create two sets for the words: a training set which contains 80% of the words and a test set which contains 20% of the words (make sure that these sets are created randomly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "english = pd.read_csv(\"CONcreTEXT_trial_EN.tsv\", sep='\\t')\n",
    "italian = pd.read_csv(\"CONcreTEXT_trial_IT.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "import random\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "englishText = []\n",
    "for i in english[\"TEXT\"]:\n",
    "    englishText += [j.lower() for j in tokenizer.tokenize(i)]\n",
    "italianText = []\n",
    "for i in italian[\"TEXT\"]:\n",
    "    italianText += [j.lower() for j in tokenizer.tokenize(i)]\n",
    "random.shuffle(englishText)\n",
    "random.shuffle(italianText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {},
   "outputs": [],
   "source": [
    "englishTrain = englishText[:int((len(englishText)+1)*.80)]\n",
    "englishTest = englishText[:int((len(englishText)+1)*.20)]\n",
    "italianTrain = italianText[:int((len(italianText)+1)*.80)]\n",
    "italianTest = italianText[:int((len(italianText)+1)*.20)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to retrieve count of a character in a list\n",
    "def getCountForCharacter(list, letter):\n",
    "    count = 0\n",
    "    for word in list:\n",
    "        count += word.count(letter)\n",
    "    return count\n",
    "\n",
    "# function to retrieve length of the text in a list\n",
    "def getLength(list):\n",
    "    count = 0\n",
    "    for word in list:\n",
    "        count += len(word)\n",
    "    return count\n",
    "\n",
    "# function to retrieve the probability of a character in a list\n",
    "def getProbability(list, letter):\n",
    "    return getCountForCharacter(list, letter) / getLength(list) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2: Next, we are going to build a unigram model for each language (English and Italian separately). Important note here: the unigrams here refer to character level unigrams. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get the dictionary of probability of characters in a list\n",
    "def getDictForUnigram(list):\n",
    "    dict = {}\n",
    "    for word in list:\n",
    "        for letter in word:\n",
    "            dict[letter] = getProbability(list, letter)\n",
    "    return dict\n",
    "\n",
    "englishTrainDictForUnigram = getDictForUnigram(englishTrain)\n",
    "italianTrainDictForUnigram = getDictForUnigram(italianTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "metadata": {},
   "outputs": [],
   "source": [
    "englishTestDictForUnigram = {}\n",
    "for word in englishTest:\n",
    "    probability = 1\n",
    "    for letter in word:\n",
    "        if englishTrainDictForUnigram[letter] != 0:\n",
    "            probability *= englishTrainDictForUnigram[letter]\n",
    "    englishTestDictForUnigram[word] = probability\n",
    "\n",
    "italianTestDictForUnigram = {}\n",
    "for word in italianTest:\n",
    "    probability = 1\n",
    "    for letter in word:\n",
    "        if italianTrainDictForUnigram[letter] !=0:\n",
    "            probability *= italianTrainDictForUnigram[letter]\n",
    "    italianTestDictForUnigram[word] = probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictDict = {}\n",
    "for key in englishTestDictForUnigram:\n",
    "    if key in italianTestDictForUnigram:\n",
    "        if englishTestDictForUnigram[key] > italianTestDictForUnigram[key]:\n",
    "            predictDict[key] = \"English\"\n",
    "        else:\n",
    "            predictDict[key] = \"Italian\"\n",
    "    else:\n",
    "        predictDict[key] = \"English\"\n",
    "\n",
    "for key in italianTestDictForUnigram:\n",
    "    if key in englishTestDictForUnigram:\n",
    "        if englishTestDictForUnigram[key] > italianTestDictForUnigram[key]:\n",
    "            predictDict[key] = \"English\"\n",
    "        else:\n",
    "            predictDict[key] = \"Italian\"\n",
    "    else:\n",
    "        predictDict[key] = \"Italian\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "resultForUnigram = Counter(predictDict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "metadata": {},
   "outputs": [],
   "source": [
    "EnglishAccuracyUnigram = (resultForUnigram['English']/len(englishTest))* 100\n",
    "# ItalianAccuracyUnigram = (resultForUnigram['Italian']/len(italianTest))* 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of English in the test set for Unigram is  67.68060836501901\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy of English in the test set for Unigram is \",EnglishAccuracyUnigram)\n",
    "# print(\"The accuracy of Italian in the test set for Unigram is \",ItalianAccuracyUnigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3: Repeat the entire Question 2, but instead for a bigram character model. How did the accuracies change? Did they increase or decrease? Is a bigram character-level language model better at distinguishing language than a unigram character-level language model? Type an *original* answer with at least 50 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getDictForBiGram(list):\n",
    "#     dict = {}\n",
    "#     for word in list:\n",
    "#         for i in range(0, len(word)-1):\n",
    "#             letter = word[i:i+2]\n",
    "#             dict[letter] = getProbability(list, letter)\n",
    "#     return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "metadata": {},
   "outputs": [],
   "source": [
    "# englishTrainDictForBiGram = getDictForBiGram(englishTrain)\n",
    "# italianTrainDictForBiGram = getDictForBiGram(italianTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 927,
   "metadata": {},
   "outputs": [],
   "source": [
    "englishTestDictForBigram = {}\n",
    "for word in englishTest:\n",
    "    probability = 1\n",
    "    if(len(word) >=2):\n",
    "        for i in range(0, len(word)-1):\n",
    "            letter = word[i:i+2]\n",
    "            probability *= getCountForCharacter(englishTrain, letter) / getCountForCharacter(englishTrain, letter[0])\n",
    "        englishTestDictForBigram[word] = probability\n",
    "\n",
    "italianTestDictForBigram = {}\n",
    "for word in italianTest:\n",
    "    probability = 1\n",
    "    if(len(word) >=2):\n",
    "        for i in range(0, len(word)-1):\n",
    "            letter = word[i:i+2]\n",
    "            probability *= getCountForCharacter(italianTrain, letter) / getCountForCharacter(italianTrain, letter[0])\n",
    "        italianTestDictForBigram[word] = probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictDictForBigram = {}\n",
    "for key in englishTestDictForBigram:\n",
    "    if key in italianTestDictForBigram:\n",
    "        if englishTestDictForBigram[key] > italianTestDictForBigram[key]:\n",
    "            predictDictForBigram[key] = \"English\"\n",
    "        else:\n",
    "            predictDictForBigram[key] = \"Italian\"\n",
    "    else:\n",
    "        predictDictForBigram[key] = \"English\"\n",
    "\n",
    "for key in italianTestDictForBigram:\n",
    "    if key in englishTestDictForBigram:\n",
    "        if englishTestDictForBigram[key] > italianTestDictForBigram[key]:\n",
    "            predictDictForBigram[key] = \"English\"\n",
    "        else:\n",
    "            predictDictForBigram[key] = \"Italian\"\n",
    "    else:\n",
    "        predictDictForBigram[key] = \"Italian\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "resultForBigram = Counter(predictDictForBigram.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "metadata": {},
   "outputs": [],
   "source": [
    "EnglishAccuracyBigram = (resultForBigram['English']/len(englishTest))* 100\n",
    "# ItalianAccuracyBiigram = (resultForBigram['Italian']/len(italianTest))* 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of English in the test set for Bigram is  67.68060836501901\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy of English in the test set for Bigram is \",EnglishAccuracyBigram)\n",
    "# print(\"The accuracy of Italian in the test set for Bigram is \",ItalianAccuracyBiigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q:How did the accuracies change? Did they increase or decrease? Is a bigram character-level language model better at distinguishing language than a unigram character-level language model?\n",
    "\n",
    "A: There is a very minute difference in the accuracy of the dataset of Bigram's Model when compared with Unigram's Model. But the bigram character-level language model is better than unigram-character level language because the probability for finding a word in a data set increases when compared with the unigram character-level language model thus resulting in more accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4: Repeat the entire Question 3, but this time for a trigram character model. Is a trigram character-level language model better at distinguishing language than a bigram character-level language model? Type an *original* answer with at least 50 words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getDictForTriGram(list):\n",
    "#     dict = {}\n",
    "#     for word in list:\n",
    "#         for i in range(0, len(word)-2):\n",
    "#             letter = word[i:i+3]\n",
    "#             dict[letter] = getProbability(list, letter) / getProbability(list, letter[:2])\n",
    "#     return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "metadata": {},
   "outputs": [],
   "source": [
    "# englishTrainDictForTriGram = getDictForTriGram(englishTrain)\n",
    "# italianTrainDictForTriGram = getDictForTriGram(italianTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "metadata": {},
   "outputs": [],
   "source": [
    "englishTestDictForTriGram = {}\n",
    "for word in englishTest:\n",
    "    probability = 1\n",
    "    if(len(word) >= 3):\n",
    "        for i in range(0, len(word)-2):\n",
    "            letter = word[i:i+3]\n",
    "            if(getCountForCharacter(englishTrain, letter[:2]) > 0):\n",
    "                probability *= getCountForCharacter(englishTrain, letter) / getCountForCharacter(englishTrain, letter[:2])\n",
    "        englishTestDictForTriGram[word] = probability\n",
    "\n",
    "italianTestDictForTriGram = {}\n",
    "for word in italianTest:\n",
    "    probability = 1\n",
    "    if(len(word) >= 3):\n",
    "        for i in range(0, len(word)-2):\n",
    "            letter = word[i:i+3]\n",
    "            if(getCountForCharacter(italianTrain, letter[:2]) > 0):\n",
    "                probability *= getCountForCharacter(italianTrain, letter) / getCountForCharacter(italianTrain, letter[:2])\n",
    "        italianTestDictForTriGram[word] = probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictDictForTriGram = {}\n",
    "for key in englishTestDictForTriGram:\n",
    "    if key in italianTestDictForTriGram:\n",
    "        if englishTestDictForTriGram[key] > italianTestDictForTriGram[key]:\n",
    "            predictDictForTriGram[key] = \"English\"\n",
    "        else:\n",
    "            predictDictForTriGram[key] = \"Italian\"\n",
    "    else:\n",
    "        predictDictForTriGram[key] = \"English\"\n",
    "\n",
    "for key in italianTestDictForTriGram:\n",
    "    if key in englishTestDictForTriGram:\n",
    "        if englishTestDictForTriGram[key] > italianTestDictForTriGram[key]:\n",
    "            predictDictForTriGram[key] = \"English\"\n",
    "        else:\n",
    "            predictDictForTriGram[key] = \"Italian\"\n",
    "    else:\n",
    "        predictDictForTriGram[key] = \"Italian\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "resultForTriGram = Counter(predictDictForTriGram.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "metadata": {},
   "outputs": [],
   "source": [
    "EnglishAccuracyTrigram = (resultForTriGram['English']/len(englishTest))* 100\n",
    "# ItalianAccuracyTrigram = (resultForTriGram['Italian']/len(italianTest))* 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of English in the test set for Trigram is  62.3574144486692\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy of English in the test set for Trigram is \",EnglishAccuracyTrigram)\n",
    "# print(\"The accuracy of Italian in the test set for Trigram is \",ItalianAccuracyTrigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: Is a trigram character-level language model better at distinguishing language than a bigram character-level language model? \n",
    "\n",
    "A: Trigram character-level language model is better in distinguishing language than the bigram character-level model. An interesting observation which I found is that in the trigram character-level language model, the accuracy has a large amount of when compared to Unigram's Model. I think the outcome of this accuracy is because the dataset provided is very less and the test data while predicting does not have enough amount of data, thus resulting in less amount of training of the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
