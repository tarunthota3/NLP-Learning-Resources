{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_8_801164383.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDMOF-H41xp4"
      },
      "source": [
        "# Assignment 8 - NMT Skeleton\n",
        "\n",
        "The aim of this homework is to familiarize you with sequence-to-sequence language modeling, specifically using an encoder-decoder model. In this notebook, you are provided with pre-written code for a simple sequence-to-sequence model that already works and learns how to reverse short sequences of numbers.\n",
        "\n",
        "If you run this whole jupyter notebook, it will learn to reverse short sequences of numbers. Although much of this code you will not be modifying, we recommend reading through it to get a sense of how the model and training works.\n",
        "\n",
        "This starter code is based on [this tutorial](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html) by Sean Robertson from the PyTorch website and the COMS course at Columbia University by Professor Kathy McKeown. \n",
        "\n",
        "### Overview\n",
        "\n",
        "Your assignment is to:\n",
        " 1. adapt this notebook to work on the English-Italian language pair from Tataoeba website\n",
        " 2. Implement a beam search function\n",
        " \n",
        "\n",
        "Write all your code **in this jupyter notebook**. Cells are provided where you should be implementing your code. \n",
        "\n",
        "You do not need to modify any code to train the model. You may modify the `trainIters` function, if you would like to improve how you track progress, or change parameters while training. For example, it can be useful to decrease the teacher-forcing ratio as training progresses.\n",
        "\n",
        "\n",
        "I would recommend you run this notebook as it is, first. You should be able to run it with the dummy data provided without making ANY modifications (except the cell where the data are loaded). Then, start making your changes as requested.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WEs4FUgr4uE"
      },
      "source": [
        "#!pip install torchtext "
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQESKYGw1xp6"
      },
      "source": [
        "# You may modify this cell if you like\n",
        "\n",
        "import random\n",
        "import time\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import torchtext\n",
        "import operator\n",
        "import torch.nn as nn\n",
        "from queue import PriorityQueue"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1F6op_f1xp9",
        "outputId": "1a12cd78-73aa-4089-9718-269b2c40f702"
      },
      "source": [
        "# DO NO MODIFY\n",
        "\n",
        "# this is useful for checking if your code is successfully using the GPU\n",
        "\n",
        "mydevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "mydevice"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbUybDZ91xp_"
      },
      "source": [
        "# DO NOT MODIFY\n",
        "\n",
        "SOS_TOKEN = '<sos>'\n",
        "EOS_TOKEN = '<eos>'\n",
        "\n",
        "MAX_LEN = 50\n",
        "\n",
        "def len_filter(example):\n",
        "    return len(example.src) <= MAX_LEN and len(example.tgt) <= MAX_LEN"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cogsJCg51xqE"
      },
      "source": [
        "### Load dummy number reversal dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3yyYL6esBZo"
      },
      "source": [
        "#note that my files were stored in google drive and I was using google colab to run this notebook\n",
        "#you can change this cell to provide local path to load your training and dev data\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# train_path = '/content/drive/My Drive/COURSES/2020/data/train/data.txt'\n",
        "# dev_path = '/content/drive/My Drive/COURSES/2020/data/dev/data.txt'\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3Z0rO701xqH"
      },
      "source": [
        "### 1. Load the data (10 points)\n",
        "\n",
        "Load in the en-it data from http://www.manythings.org/anki/ita-eng.zip\n",
        "\n",
        " similar to how the dummy number reversal dataset is loaded above. That is, use the same `torchtext.data.Field` and `torchtext.data.TabularDataset` classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zr76n7W1xqI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "ae2eb917-62ba-4aa0-f633-5f36ff44d11d"
      },
      "source": [
        "headers = ['English', 'Italian', 'Details']\n",
        "df = pd.read_csv('ita.txt', sep='\\t', names=headers)\n",
        "df1 = df[['English','Italian']]\n",
        "df1"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Italian</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Ciao!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corri!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corra!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Correte!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Who?</td>\n",
              "      <td>Chi?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>341549</th>\n",
              "      <td>If you want to sound like a native speaker, yo...</td>\n",
              "      <td>Se vuoi sembrare un madrelingua, devi essere d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>341550</th>\n",
              "      <td>If you want to sound like a native speaker, yo...</td>\n",
              "      <td>Se vuoi sembrare un madrelingua, devi essere d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>341551</th>\n",
              "      <td>If someone who doesn't know your background sa...</td>\n",
              "      <td>Se qualcuno che non conosce il tuo background ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>341552</th>\n",
              "      <td>Doubtless there exists in this world precisely...</td>\n",
              "      <td>Senza dubbio esiste in questo mondo proprio la...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>341553</th>\n",
              "      <td>Doubtless there exists in this world precisely...</td>\n",
              "      <td>Senza dubbio esiste in questo mondo proprio la...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>341554 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  English                                            Italian\n",
              "0                                                     Hi.                                              Ciao!\n",
              "1                                                    Run!                                             Corri!\n",
              "2                                                    Run!                                             Corra!\n",
              "3                                                    Run!                                           Correte!\n",
              "4                                                    Who?                                               Chi?\n",
              "...                                                   ...                                                ...\n",
              "341549  If you want to sound like a native speaker, yo...  Se vuoi sembrare un madrelingua, devi essere d...\n",
              "341550  If you want to sound like a native speaker, yo...  Se vuoi sembrare un madrelingua, devi essere d...\n",
              "341551  If someone who doesn't know your background sa...  Se qualcuno che non conosce il tuo background ...\n",
              "341552  Doubtless there exists in this world precisely...  Senza dubbio esiste in questo mondo proprio la...\n",
              "341553  Doubtless there exists in this world precisely...  Senza dubbio esiste in questo mondo proprio la...\n",
              "\n",
              "[341554 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsifloyIxraa"
      },
      "source": [
        "import numpy as np\n",
        "train, dev, test = \\\n",
        "              np.split(df1.sample(frac=1, random_state=42), \n",
        "                       [int(.6*len(df)), int(.8*len(df))])\n",
        "train.to_csv(\"train.tsv\", sep=\"\\t\",index=False)\n",
        "dev.to_csv(\"dev.tsv\", sep=\"\\t\",index=False)\n",
        "test.to_csv(\"test.tsv\", sep=\"\\t\",index=False)\n",
        "\n",
        "train_path = 'train.tsv'\n",
        "dev_path = 'dev.tsv'"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lD0JKNExxsLh"
      },
      "source": [
        "src = torchtext.data.Field(\n",
        "    batch_first=True, \n",
        "    include_lengths=True\n",
        "    )\n",
        "tgt = torchtext.data.Field(\n",
        "    batch_first=True, \n",
        "    preprocessing = lambda seq: [SOS_TOKEN] + seq + [EOS_TOKEN]\n",
        "    )\n",
        "\n",
        "data_train = torchtext.data.TabularDataset(\n",
        "        path=train_path, format='tsv',\n",
        "        fields=[('src', src), ('tgt', tgt)],\n",
        "        filter_pred=len_filter\n",
        "    )\n",
        "data_dev = torchtext.data.TabularDataset(\n",
        "        path=dev_path, format='tsv',\n",
        "        fields=[('src', src), ('tgt', tgt)],\n",
        "        filter_pred=len_filter\n",
        ")"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqisn6dd1xqK"
      },
      "source": [
        "Have a look at the vocab and some example data points.\n",
        "\n",
        "*If you have loaded in the data correctly, the code in the cell below should work without any modification.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yw7eK-hj1xqL",
        "outputId": "24883cac-584c-4ea4-b7bc-edec8d0f9e0b"
      },
      "source": [
        "# You may modify this cell if you like\n",
        "# Note the sample output - all words no numbers\n",
        "src.build_vocab(data_train, max_size=50000)\n",
        "tgt.build_vocab(data_train, max_size=50000)\n",
        "input_vocab = src.vocab\n",
        "output_vocab = tgt.vocab\n",
        "\n",
        "print('20 tokens from input vocab:\\n', list(input_vocab.stoi.keys())[:20])\n",
        "print('\\n20 tokens from output vocab:\\n', list(output_vocab.stoi.keys())[:20])\n",
        "\n",
        "print('\\nnum training examples:', len(data_train.examples))\n",
        "\n",
        "item = random.choice(data_train.examples)\n",
        "print('\\nexample train data:')\n",
        "print('src:\\n', item.src)\n",
        "print('tgt:\\n', item.tgt)\n",
        "\n",
        "#showing output below for toy dataset"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20 tokens from input vocab:\n",
            " ['<unk>', '<pad>', 'I', 'Tom', 'to', 'you', 'a', 'the', 'is', 'in', \"I'm\", 'was', 'of', 'have', 'You', 'that', 'do', 'be', 'for', 'He']\n",
            "\n",
            "20 tokens from output vocab:\n",
            " ['<unk>', '<pad>', '<eos>', '<sos>', 'Tom', 'di', 'è', 'a', 'non', 'che', 'Io', 'Non', 'un', 'la', 'il', 'ha', 'per', 'in', 'sono', 'una']\n",
            "\n",
            "num training examples: 204932\n",
            "\n",
            "example train data:\n",
            "src:\n",
            " [\"I'd\", 'like', 'some', 'cider,', 'please.']\n",
            "tgt:\n",
            " ['<sos>', 'Vorrei', 'un', \"po'\", 'di', 'sidro,', 'per', 'favore.', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7ZGeEix1xqN"
      },
      "source": [
        "### Model definition and training functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDN_VycQ1xqO"
      },
      "source": [
        "# DO NOT MODIFY\n",
        "\n",
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, myinput, hidden):\n",
        "        embedded = self.embedding(myinput).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=mydevice)\n",
        "\n",
        "    \n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=mydevice)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aA1Xp8Jb1xqR"
      },
      "source": [
        "# DO NOT MODIFY\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion,\n",
        "          max_length=MAX_LEN, teacher_forcing_ratio=0.5):\n",
        "    \n",
        "    # get an initial hidden state for the encoder\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    # zero the gradients of the optimizers\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    # get the seq lengths, used for iterating through encoder/decoder\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    # create empty tensor to fill with encoder outputs\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=mydevice)\n",
        "\n",
        "    # create a variable for loss\n",
        "    loss = 0\n",
        "    \n",
        "    # pass the inputs through the encoder\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    # create a start-of-sequence tensor for the decoder\n",
        "    decoder_input = torch.tensor([[output_vocab.stoi[SOS_TOKEN]]], device=mydevice)\n",
        "\n",
        "    # set the decoder hidden state to the final encoder hidden state\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    # decide if we will use teacher forcing\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    for di in range(target_length):\n",
        "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "        \n",
        "        topv, topi = decoder_output.topk(1)\n",
        "        decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "                \n",
        "        loss += criterion(decoder_output, target_tensor[di].unsqueeze(0))\n",
        "        \n",
        "        if use_teacher_forcing:\n",
        "            decoder_input = target_tensor[di]\n",
        "        \n",
        "        if decoder_input.item() == output_vocab.stoi[EOS_TOKEN]:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fvIGMXl1xqT"
      },
      "source": [
        "# You may modify this cell\n",
        "\n",
        "def trainIters(encoder, decoder, n_iters, print_every=1000, learning_rate=0.01, teacher_forcing_ratio=0.5):\n",
        "    print(f'Running {n_iters} epochs...')\n",
        "    print_loss_total = 0\n",
        "    print_loss_epoch = 0\n",
        "\n",
        "    encoder_optim = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optim = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "\n",
        "    # note batch size of 1, just for simplicity\n",
        "    # DO NOT INCREASE THE BATCH SIZE\n",
        "    batch_iterator = torchtext.data.Iterator(\n",
        "        dataset=data_train, batch_size=1,\n",
        "        sort=False, sort_within_batch=True,\n",
        "        sort_key=lambda x: len(x.src),\n",
        "        device=mydevice, repeat=False)\n",
        "    \n",
        "\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for e in range(n_iters):\n",
        "        batch_generator = batch_iterator.__iter__()\n",
        "        step = 0\n",
        "        start = time.time()\n",
        "        for batch in batch_generator:\n",
        "            step += 1\n",
        "            \n",
        "            # get the input and target from the batch iterator\n",
        "            input_tensor, input_lengths = getattr(batch, 'src')\n",
        "            target_tensor = getattr(batch, 'tgt')\n",
        "            \n",
        "            # this is because we're not actually using the batches.\n",
        "            # batch size is 1 and this just selects that first one\n",
        "            input_tensor = input_tensor[0]\n",
        "            target_tensor = target_tensor[0]\n",
        "\n",
        "            loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optim, decoder_optim, criterion, teacher_forcing_ratio=teacher_forcing_ratio)\n",
        "            print_loss_total += loss\n",
        "            print_loss_epoch += loss\n",
        "            \n",
        "\n",
        "            if step % print_every == 0:\n",
        "                print_loss_avg = print_loss_total / print_every\n",
        "                print_loss_total = 0\n",
        "                t = (time.time() - start) / 60\n",
        "                print(f'step: {step}\\t avg loss: {print_loss_avg:.2f}\\t time for {print_every} steps: {t:.2f} min')\n",
        "                start = time.time()\n",
        "        \n",
        "        print_loss_avg = print_loss_epoch / step\n",
        "        print_loss_epoch = 0\n",
        "        print(f'End of epoch {e}, avg loss {print_loss_avg:.2f}')  "
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CYrxT_n1xqV"
      },
      "source": [
        "###  Create and train a model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyPIjhkcr4uH"
      },
      "source": [
        "## Download Pre-trained Encoder-Decoder\n",
        "\n",
        "Use the following GDrive links to download a pre-trained Encoder-Decoder models so you don't have to train it yourself:\n",
        "- [Encoder](https://drive.google.com/file/d/1H27fmP9pPwP5N__ESJXOYWZ-ThIV8LBc/view?usp=sharing)\n",
        "- [Decoder](https://drive.google.com/file/d/1-3opHrQzC2zBO9ZaYPkx5F-i_-f1JrmB/view?usp=sharing)\n",
        "\n",
        "These links will give you two files `encoder.pt` and `decoder.pt` you'd want to put them in the same directory is the notebook and run the cell below. This takes away the need for you to wait for a completed training of the model using the complete dataset. The pre-trained model params are:\n",
        "- For both the encoder and decoder `hidden_state` = 128\n",
        "- Encoder `input_size` = 25,030\n",
        "- Decoder `output_size` = 46,754\n",
        "\n",
        "If you want a different hidden_size/on your own dataset split you have to train the model yourself because you won't be able to use the pre-trained model.\n",
        "\n",
        "**Note** - Ensure you have the params above when you instantiate EncoderRNN and DecoderRNN for you to be able to load the params properly.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOBbHdMM1xqV"
      },
      "source": [
        "# You may modify this cell\n",
        "\n",
        "hidden_size = 128\n",
        "encoder1 = EncoderRNN(25030,hidden_size).to(mydevice)\n",
        "decoder1 = DecoderRNN(hidden_size, 46754).to(mydevice)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPLnjxOvr4uH",
        "outputId": "fd59505d-4557-4f6e-d11e-65de11bc6ddf"
      },
      "source": [
        "# Load pre-trained encoder and decoder\n",
        "# Reference: https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
        "# trainIters(encoder1, decoder1, 1, print_every=1000, teacher_forcing_ratio=0.75)\n",
        "encoder1.load_state_dict(torch.load('encoder.pt'))\n",
        "decoder1.load_state_dict(torch.load('decoder.pt'))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCKVT2Y11xqX"
      },
      "source": [
        "Here are some guidelines for how much training to expect. Note that these *guidelines*; they are not exact.\n",
        "\n",
        "Only 1 epoch is needed for the number reversal dataset. This produces near-perfect results, and should take less than 5 minutes to run on a CPU.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCAZ8hbk1xqY"
      },
      "source": [
        "# You may modify this cell\n",
        "# but be sure that it prints some indication of how training is progressing\n",
        "# Training is optional if you load the pre-trained Encoder-Decoder\n",
        "\n",
        "\n",
        "#trainIters(encoder1, decoder1, 1, print_every=1000, teacher_forcing_ratio=0.75)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2G_5Uwx1xqg"
      },
      "source": [
        "# DO NOT MODIFY\n",
        "\n",
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LEN):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = torch.tensor([input_vocab.stoi[word] for word in sentence], device=mydevice)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=mydevice)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[output_vocab.stoi[SOS_TOKEN]]], device=mydevice)\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            print(type(topi))\n",
        "            next_word = output_vocab.itos[topi.item()]\n",
        "            decoded_words.append(next_word)\n",
        "            if next_word == EOS_TOKEN:\n",
        "                break\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDG-Sydz1xql"
      },
      "source": [
        "Have a look at some generated sequences! This is the fun part."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWPksDgH1xqm",
        "outputId": "04c04fee-eaf0-4fae-eaac-0da51e01f230"
      },
      "source": [
        "# You may modify this cell\n",
        "# This is to ensure all the steps above were done correctly - should see sensical output\n",
        "# This selects 5 random datapoints from the training data and shows the generated sequence\n",
        "\n",
        "for i in range(5):\n",
        "    item = random.choice(data_train.examples)\n",
        "    seq = item.src\n",
        "    print(seq)\n",
        "    words = evaluate(encoder1, decoder1, seq)\n",
        "    print(' '.join(words))\n",
        "    print()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['When', 'does', 'this', 'plane', 'reach', 'Boston?']\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<sos> me sono ma di detto francese È <eos>\n",
            "\n",
            "['I', \"don't\", 'need', 'any', 'help.']\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<sos> Non mi casa ancora <eos>\n",
            "\n",
            "['Tom', 'said', 'he', 'was', 'so', 'sorry.']\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<sos> Tom è un quello che lavoro. sia un quello <eos>\n",
            "\n",
            "['I', \"don't\", 'like', 'this', 'idea.']\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<sos> Non sono sono <eos>\n",
            "\n",
            "['I', \"don't\", 'know', 'what', 'his', 'name', 'is.']\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "<sos> Io non gli Tom? che il sua sua <eos>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-owLs3W1xqn"
      },
      "source": [
        "### Implement beam search (10 points for ITCS 4111 students, 15 points for the ITCS 5111/DSBA 6010 students)\n",
        "\n",
        "We provide an evaluation function that performs greedy decoding on any input sequence provided. \n",
        "\n",
        "(ITCS 4111 students) You must write a new  function that implements beam search for a beam size = 2. \n",
        "\n",
        "(ITCS 5111/DSBA 6010 students) You must write a new  function that implements beam search for an arbitrary beam size. Let the beam size be an input parameter to your function. \n",
        "\n",
        "In greedy decoding, at each decoding step the most likely word is selected, resulting in one decoded sequence output. \n",
        "\n",
        "In beam search, at each decoding step the top k most\n",
        "likely sequences are selected. Each of these k sequences is then used to generate the next step; the top k next words per sequence are considered (for a total of k ∗ k sequences)\n",
        "and the top k sequences are selected to take to the next decoding step. At the end, you have k decoded sequence outputs.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXR5qkCtr4uH"
      },
      "source": [
        "# Beam Search Node adapted from: \n",
        "# https://github.com/budzianowski/PyTorch-Beam-Search-Decoding/blob/master/decode_beam.py\n",
        "class BeamSearchNode(object):\n",
        "    def __init__(self, hiddenstate, previousNode, wordId, logProb, length):\n",
        "        '''\n",
        "        :param hiddenstate:\n",
        "        :param previousNode:\n",
        "        :param wordId:\n",
        "        :param logProb:\n",
        "        :param length:\n",
        "        '''\n",
        "        self.h = hiddenstate\n",
        "        self.prevNode = previousNode\n",
        "        self.wordid = wordId\n",
        "        self.logp = logProb\n",
        "        self.leng = length\n",
        "\n",
        "    def eval(self, alpha=1.0):\n",
        "        reward = 0\n",
        "        # Add here a function for shaping a reward\n",
        "        \n",
        "        return self.logp / float(self.leng - 1 + 1e-6) + alpha * reward"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RM53b6XE1xqo"
      },
      "source": [
        "# WRITE YOUR CODE FOR THE BEAM SEARCH HERE\n",
        "\n",
        "\n",
        "#there are several implementation of beam search on the web. You can adapt those for this assignment. \n",
        "#Please provide proper credit to the original source if you are doing so\n",
        "#one example is here: https://github.com/budzianowski/PyTorch-Beam-Search-Decoding/blob/master/decode_beam.py\n",
        "\n",
        "\n",
        "#you may need to add a helper function to see if your implementation of beam search works\n",
        "#add that helper function below\n",
        "\n",
        "# HINT: https://torchtext.readthedocs.io/en/latest/vocab.html - use to translate word to numbers and numbers to words\n",
        "def beam_decode(decoder_hiddens,beam_width=2):\n",
        "    '''\n",
        "    :param target_tensor: target indexes tensor of shape [B, T] where B is the batch size and T is the maximum length of the output sentence\n",
        "    :param decoder_hidden: input tensor of shape [1, B, H] for start of the decoding\n",
        "    :param encoder_outputs: if you are using attention mechanism you can pass encoder outputs, [T, B, H] where T is the maximum length of input sentence\n",
        "    :return: decoded_batch\n",
        "    '''\n",
        "    topk = 1  # how many sentence do you want to generate\n",
        "    decoded_batch=[]\n",
        "    utterances=[]\n",
        "    for idx in range(1):\n",
        "        if isinstance(decoder_hiddens, tuple):  # LSTM case\n",
        "            decoder_hidden = (decoder_hiddens[0][:,idx, :].unsqueeze(0),decoder_hiddens[1][:,idx, :].unsqueeze(0))\n",
        "        else:\n",
        "            decoder_hidden = decoder_hiddens[:, idx, :].unsqueeze(0)\n",
        "        # Start with the start of the sentence token\n",
        "        decoder_input = torch.tensor([[output_vocab.stoi[SOS_TOKEN]]], device=mydevice)\n",
        "        \n",
        "        # Number of sentence to generate\n",
        "        endnodes = []\n",
        "        number_required = min((topk + 1), topk - len(endnodes))\n",
        "\n",
        "        # starting node -  hidden vector, previous node, word id, logp, length\n",
        "        node = BeamSearchNode(decoder_hidden, None, decoder_input, 0, 1)\n",
        "        nodes = PriorityQueue()\n",
        "\n",
        "        # start the queue\n",
        "        nodes.put((-node.eval(), node))\n",
        "        qsize = 1\n",
        "\n",
        "        # start beam search\n",
        "        while True:\n",
        "            # give up when decoding takes too long\n",
        "            if qsize > 2000: break\n",
        "\n",
        "            # fetch the best node\n",
        "            score, n = nodes.get()\n",
        "            decoder_input = n.wordid\n",
        "            decoder_hidden = n.h\n",
        "            \n",
        "            if n.wordid.item() == EOS_TOKEN and n.prevNode != None:\n",
        "                endnodes.append((score, n))\n",
        "                # if we reached maximum # of sentences required\n",
        "                if len(endnodes) >= number_required:\n",
        "                    break\n",
        "                else:\n",
        "                    continue\n",
        "\n",
        "            #TODO: use the trained decoder (decoder1) to decode using the input (starting with SOS) \n",
        "            # and decoder_hidden to get the decoder output and the decoder hidden weights for the new input.\n",
        "            \n",
        "            decoder_output, decoder_hidden = decoder1(decoder_input, decoder_hidden)\n",
        "\n",
        "            # PUT HERE REAL BEAM SEARCH OF TOP\n",
        "            # HINT Reference: https://pytorch.org/docs/stable/generated/torch.topk.html\n",
        "            #TODO: get get the top [beam size] most likely decoder_outputs and store their probabilities and indexes\n",
        "            log_prob, indexes = torch.topk(decoder_output, beam_width)\n",
        "            \n",
        "            nextnodes = []\n",
        "\n",
        "            for new_k in range(beam_width):\n",
        "                decoded_t = indexes[0][new_k].view(1, -1)\n",
        "                log_p = log_prob[0][new_k].item()\n",
        "\n",
        "                node = BeamSearchNode(decoder_hidden, n, decoded_t, n.logp + log_p, n.leng + 1)\n",
        "                score = -node.eval()\n",
        "                nextnodes.append((score, node))\n",
        "\n",
        "            # put them into queue\n",
        "            for i in range(len(nextnodes)):\n",
        "                score, nn = nextnodes[i]\n",
        "                nodes.put((score, nn))\n",
        "                # increase qsize\n",
        "            qsize += len(nextnodes) - 1\n",
        "\n",
        "        # choose nbest paths, back trace them\n",
        "        if len(endnodes) == 0:\n",
        "            endnodes = [nodes.get() for _ in range(topk)]\n",
        "\n",
        "        for score, n in sorted(endnodes, key=operator.itemgetter(0)):\n",
        "            utterance = []\n",
        "            #TODO: convert the node id to a word\n",
        "            utterance.append(n.wordid)\n",
        "            #TODO: store decoded word in utterance\n",
        "            # back trace\n",
        "            while n.prevNode != None:\n",
        "                n = n.prevNode\n",
        "                utterance.append(n.wordid)\n",
        "                #TODO: get previous node\n",
        "                #TODO convert node id to word\n",
        "                # store decoded word in utterance\n",
        "            utterance = utterance[::-1]\n",
        "            utterances.append(utterance)\n",
        "        return utterance\n",
        "\n",
        "\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_572U2Jr4uH"
      },
      "source": [
        "# HINT: Refer to the evaluate function to preprocess and encode the input sentence \n",
        "# and to prepare for the decoding process\n",
        "def decoder_helper(encoder,decoder,sentence,max_length=MAX_LEN,beam_width = 2):\n",
        "    \n",
        "    # TODO: Disable autograd through the whole method - we are only computing outputs and not updating weights.\n",
        "            # Recall the PyTorch tutorial video\n",
        "    with torch.no_grad():\n",
        "        input_tensor = torch.tensor([input_vocab.stoi[word] for word in sentence], device=mydevice)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=mydevice)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[output_vocab.stoi[SOS_TOKEN]]], device=mydevice)\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "    # TODO: Create an input tensor containing the id's for each word in the sentence argument\n",
        "    # TODO: Initialize the encoder hidden layer\n",
        "    # TODO: Store the number of words in the variable input_length\n",
        "    # TODO: Loop through all the input words and encode them using the trained encoder\n",
        "    # TODO: After the loop is over pass on the hidden weights from the encoder to the decoder\n",
        "    \n",
        "    \n",
        "        \n",
        "\n",
        "        return beam_decode(decoder_hidden,beam_width)\n",
        "    "
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6h_UOn-Mr4uH",
        "outputId": "5fa551e8-831d-4bf8-af61-badea59b032e"
      },
      "source": [
        "# You may modify this cell\n",
        "\n",
        "# This selects 10 random datapoints from the training data and shows the generated sequence\n",
        "\n",
        "for i in range(10):\n",
        "    item = random.choice(data_train.examples)\n",
        "    seq = item.src\n",
        "    tg = item.tgt\n",
        "    print(f\"Source Sentence: {' '.join(seq)}\")\n",
        "    words = decoder_helper(encoder1,decoder1,seq,beam_width = 2)\n",
        "    print(f\"Predicted Sentence: {' '.join([output_vocab.itos[w.item()] for w in words if output_vocab.itos[w.item()] not in [SOS_TOKEN,EOS_TOKEN]])}\")\n",
        "    print(f\"Target Sentence: {' '.join(tg)}\")\n",
        "    print()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Source Sentence: Tom has nothing to hide.\n",
            "Predicted Sentence: Tom mi ha con\n",
            "Target Sentence: <sos> Tom non ha nulla da nascondere. <eos>\n",
            "\n",
            "Source Sentence: Today, I went to the doctor's.\n",
            "Predicted Sentence: Io non ho la\n",
            "Target Sentence: <sos> Oggi sono andato dal dottore. <eos>\n",
            "\n",
            "Source Sentence: I eat everything.\n",
            "Predicted Sentence: Io mi nostro\n",
            "Target Sentence: <sos> Mangio tutto. <eos>\n",
            "\n",
            "Source Sentence: Come here, Tom.\n",
            "Predicted Sentence: hai colpa\n",
            "Target Sentence: <sos> Vieni qui, Tom. <eos>\n",
            "\n",
            "Source Sentence: Tom's grinning.\n",
            "Predicted Sentence: Non è vero?\n",
            "Target Sentence: <sos> Tom sta sorridendo. <eos>\n",
            "\n",
            "Source Sentence: Tom was married.\n",
            "Predicted Sentence: Tom è biblioteca.\n",
            "Target Sentence: <sos> Tom era sposato. <eos>\n",
            "\n",
            "Source Sentence: We want peace.\n",
            "Predicted Sentence: Noi durante\n",
            "Target Sentence: <sos> Vogliamo la pace. <eos>\n",
            "\n",
            "Source Sentence: Under the circumstances, bankruptcy is inevitable.\n",
            "Predicted Sentence: Mary messo che il Ne è il il\n",
            "Target Sentence: <sos> Sotto le circostanze, la bancarotta è inevitabile. <eos>\n",
            "\n",
            "Source Sentence: You're a weirdo.\n",
            "Predicted Sentence: 2013. un una\n",
            "Target Sentence: <sos> È un tipo strano. <eos>\n",
            "\n",
            "Source Sentence: Tom had to walk home since his car broke down.\n",
            "Predicted Sentence: Tom si è Devo fare Lo con il sua\n",
            "Target Sentence: <sos> Tom è dovuto andare a casa a piedi dopo che la sua macchina si è rotta. <eos>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}